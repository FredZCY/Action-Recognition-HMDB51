{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbPNgrjUdH3G"
      },
      "source": [
        "## **Step 1 Download and Extract the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tiCaNE-0Kf4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3cc022-ab76-4b32-d1c6-074f5eacabad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/JHU2022SPRING/DeepLearningProject_Erix\n",
            "hmdb51_org  hmdb51_org.rar  model_structure_plot.png\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/JHU2022SPRING/DeepLearningProject_Erix\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Iz5MyJOO-Hr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14afc016-b855-4ca6-f21a-70a41e8effc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  3 22:33:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcILvhFJapS4",
        "outputId": "2d8c739a-b7ab-4947-b217-1b1f21e5f7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hmdb51_org.rar  has Not downloaded Yet, Wait......\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "file_name='hmdb51_org.rar'\n",
        "if os.path.exists(file_name):\n",
        "  print(file_name, \" has been already downloaded\")\n",
        "else:\n",
        "  print(file_name, \" has Not downloaded Yet, Wait......\")\n",
        "  os.system(f\"\"\"wget -c --read-timeout=5 --tries=0 http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\"\"\")\n",
        "\n",
        "!pip install unrar\n",
        "!mkdir hmdb51_org\n",
        "get_ipython().system_raw(\"unrar x hmdb51_org.rar hmdb51_org\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "G18anvrp00QN",
        "outputId": "44c786b9-8813-4e1b-e0bc-ff7ffeac93f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/JHU2022SPRING/DeepLearningProject_Erix/hmdb51_org/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd() + '/hmdb51_org/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsiuoqgq1DvY",
        "outputId": "480b9fbb-c7f7-4587-d0d0-7748d45166cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mhmdb51_org\u001b[0m/  hmdb51_org.rar  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5KPTFiciiau"
      },
      "outputs": [],
      "source": [
        "import glob as g\n",
        "import os\n",
        "path=os.getcwd() + '/hmdb51_org/'\n",
        "data_files = []\n",
        "for i in g.glob( path+ '/**/*.rar',recursive=True):\n",
        "    data_files.append(i)\n",
        "data_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyqXQrbEmJ5p"
      },
      "outputs": [],
      "source": [
        "for file in tqdm(data_files):\n",
        "  get_ipython().system_raw(\"unrar x {} hmdb51_org\".format(file))\n",
        "  os.remove(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiAMJx7tr5-I"
      },
      "source": [
        "#### **Import Required Libraries:**\n",
        "Start by importing all required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X3AdbpZFCRR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27eaa2e2-ea8c-40fa-c04d-a63dbffa1f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3063808/45929032 bytes (6.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7086080/45929032 bytes (15.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11321344/45929032 bytes (24.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15368192/45929032 bytes (33.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19439616/45929032 bytes (42.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23633920/45929032 bytes (51.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27820032/45929032 bytes (60.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32014336/45929032 bytes (69.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36200448/45929032 bytes (78.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40435712/45929032 bytes (88.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44679168/45929032 bytes (97.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ],
      "source": [
        "# run\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from moviepy.editor import *\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from math import floor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT1dZY7cD3Ro"
      },
      "source": [
        "**Set Numpy, Python & Tensorflow seeds to get consistent results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3pEI_v7HD1WV"
      },
      "outputs": [],
      "source": [
        "seed_constant = 23\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQnKb7fbC2aq"
      },
      "outputs": [],
      "source": [
        "# # Create a Matplotlib figure\n",
        "# plt.figure(figsize = (50, 50))\n",
        "\n",
        "# # Get Names of all classes in hmdb51_org\n",
        "# all_classes_names = os.listdir('hmdb51_org')\n",
        "\n",
        "# # Generate a random sample of images each time the cell runs\n",
        "# random_range = random.sample(range(len(all_classes_names)), 51)\n",
        "\n",
        "# # Iterating through all the random samples\n",
        "# for counter, random_index in enumerate(random_range, 1):\n",
        "\n",
        "#     # Getting Class Name using Random Index\n",
        "#     selected_class_Name = all_classes_names[random_index]\n",
        "\n",
        "#     # Getting a list of all the video files present in a Class Directory\n",
        "#     video_files_names_list = os.listdir(f'hmdb51_org/{selected_class_Name}')\n",
        "\n",
        "#     # Randomly selecting a video file\n",
        "#     selected_video_file_name = random.choice(video_files_names_list)\n",
        "\n",
        "#     # Reading the Video File Using the Video Capture\n",
        "#     video_reader = cv2.VideoCapture(f'hmdb51_org/{selected_class_Name}/{selected_video_file_name}')\n",
        "    \n",
        "#     # Reading The First Frame of the Video File\n",
        "#     _, bgr_frame = video_reader.read()\n",
        "\n",
        "#     # Closing the VideoCapture object and releasing all resources. \n",
        "#     video_reader.release()\n",
        "\n",
        "#     # Converting the BGR Frame to RGB Frame \n",
        "#     rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     # Adding The Class Name Text on top of the Video Frame.\n",
        "#     cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    \n",
        "#     # Assigning the Frame to a specific position of a subplot\n",
        "#     plt.subplot(11, 5, counter)\n",
        "#     plt.imshow(rgb_frame)\n",
        "#     plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IolruUHP16m5",
        "outputId": "237118c2-3b5c-4d50-94a8-4c4782d67200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10875468119064278094\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 16154099712\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 8152170386231438943\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "xla_global_id: 416903419\n",
            "]\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "b4gmOHQcPZjc",
        "outputId": "9ae8fea8-cc51-4552-ad15-65b52b36a921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/JHU2022SPRING/DeepLearningProject_Erix/hmdb51_org/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jNu1QTX0G0q"
      },
      "source": [
        "Calling the **create_dataset** method which returns features and labels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# erix dataprocessing edition 2, avoid ram crash when splitting tran/test..\n",
        "# erix cell, get training and testing set \n",
        "image_height, image_width = 64, 64\n",
        "max_images_per_class = 2000\n",
        "dataset_directory = \"/content/drive/MyDrive/JHU2022SPRING/DeepLearningProject_Erix/hmdb51_org/\"\n",
        "#classes_list = [ 'eat', 'fall_floor', 'fencing', 'flic_flac', 'golf', 'handstand', 'sword', 'sword_exercise', 'walk', 'hit', 'shoot_ball', 'shoot_bow', 'shoot_gun', 'sit', 'situp', 'smile', 'smoke', 'somersault', 'stand', 'swing_baseball', 'hug', 'jump', 'kick', 'kick_ball','kiss', 'laugh', 'pick', 'pour', 'brush_hair','cartwheel', 'catch', 'chew', 'clap', 'climb', 'climb_stairs', 'dive', 'draw_sword', 'dribble','drink', 'pullup', 'punch', 'push', 'pushup', 'ride_bike', 'ride_horse', 'run', 'shake_hands']\n",
        "classes_list_all = [ 'eat', 'fall_floor', 'fencing', 'walk', 'hit', 'sit', 'situp', 'smile', 'smoke', 'stand', 'hug', 'jump', 'kick','kiss', \n",
        "                'laugh', 'pick', 'catch', 'chew', 'clap', 'climb', 'dive', 'drink', 'punch', 'push', 'ride_bike', 'run', 'shake_hands']\n",
        "# 10\n",
        "classes_list = ['wave', 'brush_hair', 'catch', 'climb', 'eat', 'pick', 'pour', 'smile', 'situp' , 'kiss']\n",
        "classes_list_15 = ['Wave', 'brush_hair', 'catch', 'climb', 'eat', 'pick', 'pour', 'smile', 'situp' , 'kiss', 'golf', 'sword', 'hit', 'shoot_ball', 'stand']  \n",
        "classes_list_20 = [] # todo? \n",
        "\n",
        "\n",
        "\n",
        "model_output_size = len(classes_list)\n",
        "\n",
        "def frames_extraction(video_path):\n",
        "    # Empty List declared to store video frames\n",
        "    frames_list = []\n",
        "    \n",
        "    # Reading the Video File Using the VideoCapture\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Iterating through Video Frames\n",
        "    while True:\n",
        "\n",
        "        # Reading a frame from the video file \n",
        "        success, frame = video_reader.read() \n",
        "\n",
        "        # If Video frame was not successfully read then break the loop\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "        \n",
        "        # Appending the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "    # Closing the VideoCapture object and releasing all resources. \n",
        "    video_reader.release()\n",
        "\n",
        "    # returning the frames list \n",
        "    return frames_list\n",
        "\n",
        "# erix func\n",
        "def get_frame_indices(target_len, frames_len):\n",
        "    res = []\n",
        "    for n_i in range(1,target_len+1):\n",
        "        res.append(floor((frames_len-1)*n_i/target_len))\n",
        "    return res\n",
        "# erix func\n",
        "\n",
        "# erix func\n",
        "# newest update.. only use a few videos\n",
        "\n",
        "frame_per_video = 13 # 40\n",
        "def sample_videos(features, labels, num_samples=6, frame_per_video=frame_per_video):\n",
        "    last_label = None\n",
        "    sampled_features = np.zeros([num_samples*frame_per_video, 64, 64, 3])\n",
        "    sampled_labels = []\n",
        "    sample_idx = 0\n",
        "    for idx, cur_label in enumerate(labels):\n",
        "        if cur_label == last_label:\n",
        "            continue\n",
        "        last_label = cur_label\n",
        "        sampled_features[sample_idx:] = features[idx]\n",
        "        sampled_features[sample_idx: + frame_per_video] = features[idx:idx + frame_per_video]\n",
        "        for j in frame_per_video:\n",
        "            sampled_labels.append(cur_label)\n",
        "    return sampled_features, sampled_labels\n",
        "\n",
        "\n",
        "# erix func\n",
        "def get_video_frames(min_num_frames=frame_per_video, classes_list=classes_list):\n",
        "\n",
        "    \n",
        "    # generate eatures_train, y = labels_train\n",
        "    test_ratio = 0.2\n",
        "    features_train = []\n",
        "    labels_train = []\n",
        "    features_test = []\n",
        "    labels_test = []\n",
        "\n",
        "\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    # each video is an np.array of size (40, 64, 64, 3)\n",
        "    # get sizes \n",
        "    train_size, test_size = 0, 0\n",
        "    for class_index, class_name in enumerate(classes_list):\n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
        "        num_videos = len(files_list)\n",
        "        for idx, file_name in enumerate(files_list):\n",
        "            if idx <= num_videos * (1-test_ratio):\n",
        "                train_size +=min_num_frames\n",
        "            else:\n",
        "                test_size +=min_num_frames\n",
        "    features_train = np.zeros([train_size, 64, 64, 3])\n",
        "    features_test = np.zeros([test_size, 64, 64, 3])\n",
        "    train_size, test_size = 0, 0\n",
        "    for class_index, class_name in enumerate(classes_list):\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        \n",
        "        # Getting the list of video files present in the specific class name directory\n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
        "        frames_per_class = []\n",
        "        num_videos = len(files_list) # number of videos of this class!\n",
        "        for idx, file_name in enumerate(files_list):\n",
        "            # Construct the complete video path\n",
        "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
        "\n",
        "            # Calling the frame_extraction method for every video file path\n",
        "            cur_video_frames = frames_extraction(video_file_path)\n",
        "\n",
        "            # \n",
        "\n",
        "            # Appending the frames to a temporary list.\n",
        "            frame_indices = get_frame_indices(min_num_frames, len(cur_video_frames))\n",
        "            cur_video_frames = [cur_video_frames[i] for i in frame_indices]\n",
        "            cur_video_frames = np.asarray(cur_video_frames)\n",
        "\n",
        "\n",
        "            if idx <= num_videos * (1-test_ratio):\n",
        "                features_train[train_size:train_size+min_num_frames] = cur_video_frames\n",
        "                labels_train.extend(min_num_frames*[class_name])\n",
        "                train_size+=min_num_frames\n",
        "            else:\n",
        "                # test set\n",
        "                features_test[test_size:test_size+min_num_frames] = cur_video_frames\n",
        "                labels_test.extend(min_num_frames*[class_name])\n",
        "                test_size+=min_num_frames\n",
        "        # if class_index==2:\n",
        "        #     break\n",
        "        # break  !! TODO: remove this break\n",
        "\n",
        "    return features_train, features_test, labels_train, labels_test\n",
        "\n",
        "\n",
        "# erix\n",
        "\n",
        "# TODO\n",
        "\n",
        "# ResNet\n",
        "# def erix_evaluate(features, labels, predictions min_num_frames=40, classes_list=classes_list):\n",
        "    \n",
        "#     for i in range(len(features//min_num_frames)):\n",
        "#         if i%\n",
        "\n",
        "# get the dictionary dataset\n",
        "features_train, features_test, labels_train, labels_test = get_video_frames(min_num_frames=13, classes_list=classes_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSaZ4tRWNPzA",
        "outputId": "22b3c823-6748-40c4-9103-b2557fbd2cbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: wave\n",
            "Extracting Data of Class: brush_hair\n",
            "Extracting Data of Class: catch\n",
            "Extracting Data of Class: climb\n",
            "Extracting Data of Class: eat\n",
            "Extracting Data of Class: pick\n",
            "Extracting Data of Class: pour\n",
            "Extracting Data of Class: smile\n",
            "Extracting Data of Class: situp\n",
            "Extracting Data of Class: kiss\n",
            "CPU times: user 1min 7s, sys: 5.11 s, total: 1min 12s\n",
            "Wall time: 1min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#erix cell, clear ram\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I6XipKBNhC-",
        "outputId": "d8882674-619c-4517-e16f-7d6faa476906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17949"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# erix note:\n",
        "# use train_split for splitting training srt\n",
        "\n",
        "def sample_videos_testset(features, labels, num_samples=6, frame_per_video=40):\n",
        "    last_label = None\n",
        "    sampled_features = np.zeros([num_samples*frame_per_video*len(classes_list), 64, 64, 3])\n",
        "    sampled_labels = []\n",
        "    sample_idx = 0\n",
        "    for idx, cur_label in enumerate(labels):\n",
        "        if cur_label == last_label:\n",
        "            continue\n",
        "        # print(idx)\n",
        "        # print(sample_idx)\n",
        "        last_label = cur_label\n",
        "        # sampled_features[sample_idx:] = features[idx]\n",
        "        sampled_features[sample_idx: sample_idx+ num_samples*frame_per_video] = features[idx:idx + num_samples*frame_per_video]\n",
        "        for j in range(num_samples*frame_per_video):\n",
        "            sampled_labels.append(cur_label)\n",
        "        sample_idx += num_samples*frame_per_video\n",
        "    return sampled_features, sampled_labels\n",
        "sampled_features, sampled_labels = sample_videos_testset(features_test, \n",
        "                                                         labels_test, num_samples=6, \n",
        "                                                         frame_per_video=13)"
      ],
      "metadata": {
        "id": "siBlgbJGealU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sampled_labels)/frame_per_video) # num videos\n",
        "print(len(sampled_labels)/frame_per_video/model_output_size)# num videos per class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X33XIfAupt2A",
        "outputId": "de0b375d-83ea-4d7d-bcba-c3e2e15ce415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108.0\n",
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verify , some number for 27 classes\n",
        "print(\"num of frames:\")\n",
        "print(len(labels_train))\n",
        "print(len(labels_test))\n",
        "\n",
        "print(\"num of videos:\")\n",
        "print(len(labels_train)/frame_per_video)\n",
        "print(len(labels_test)/frame_per_video)\n",
        "\n",
        "len(features_train) == len(labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK6IBnnAPVox",
        "outputId": "a1ce1bb1-4d72-4474-ebaf-b4f8086260a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of frames:\n",
            "40339\n",
            "9854\n",
            "num of videos:\n",
            "3103.0\n",
            "758.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfdsT8Sn4oye",
        "outputId": "2ad791b5-df3a-495c-8553-47bf815c266b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8cDSpfXJXwx",
        "outputId": "c2ed8e26-1846-4eb7-ffb0-3c1d6384f5de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 60, 60, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               16640     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 58,570\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Let's create a function that will construct our model\n",
        "def create_model():\n",
        "\n",
        "    # We will use a Sequential model for model construction\n",
        "    model = Sequential()\n",
        "\n",
        "    # Defining The Model Architecture\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
        "\n",
        "    # Printing the models summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Calling the create_model method\n",
        "model = create_model()\n",
        "\n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbSK_rKUK-xQ"
      },
      "outputs": [],
      "source": [
        "# plot_model(model, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJNSUstxyQ-a",
        "outputId": "effe3594-4fe3-4a1a-9a6a-88d0e006cc50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40339"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "metadata": {
        "id": "u_YGjpPm7h1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# erix cell\n",
        "# generate labels, and shuffle the training set\n",
        "\n",
        "class_idx_map = {}\n",
        "# map classnames to idx \n",
        "for idx, c in enumerate(classes_list):\n",
        "    class_idx_map[c] = idx\n",
        "\n",
        "\n",
        "# Erix added . Training\n",
        "class_idx_map = {}\n",
        "# convert \n",
        "for idx, c in enumerate(classes_list):\n",
        "    class_idx_map[c] = idx\n",
        "one_hot_encoded_erix_labels_train = to_categorical(list(map(lambda x: class_idx_map[x], labels_train)))\n",
        "one_hot_encoded_labels_test = to_categorical(list(map(lambda x: class_idx_map[x], labels_test)))\n",
        "\n",
        "# selected test samples\n",
        "one_hot_encoded_labels_sampled_test = to_categorical(list(map(lambda x: class_idx_map[x], sampled_labels)))\n",
        "\n",
        "# shuffle the training set!\n",
        "# there's a problem with keras shuffle! \n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "features_train_shuffle, one_hot_encoded_erix_labels_train_shuffle = unison_shuffled_copies(features_train, one_hot_encoded_erix_labels_train)\n"
      ],
      "metadata": {
        "id": "StgCidJ79Z4i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# erix cell, Baseline Model\n",
        "import gc\n",
        "gc.collect()\n",
        "# would crash.. if i have 40 frames per video (120k frames in total)\n",
        "# thus later trained on 13 frames per video.\n",
        "# shuffle is not ..random enough\n",
        "model = create_model()\n",
        "\n",
        "seed_constant = 44\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant+1)\n",
        "tf.random.set_seed(seed_constant+2)\n",
        "\n",
        "# manually shuffle the training set! model.fit(shuffle=?) is problematic.\n",
        "\n",
        "# one_hot_encoded_erix_labels_train = to_categorical(list(map(lambda x: class_idx_map[x], labels_train)))\n",
        "shuffled=True\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = features_train_shuffle, y = one_hot_encoded_erix_labels_train_shuffle, epochs = 200, \n",
        "                                   batch_size = 15 , shuffle = True, validation_split = 0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EKPO7WYLvsBS",
        "outputId": "439dab1e-33e7-471c-fc29-00c910c1d229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 60, 60, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 64)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 58,570\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "586/586 [==============================] - 5s 7ms/step - loss: 1.6047 - accuracy: 0.4513 - val_loss: 1.8255 - val_accuracy: 0.3751\n",
            "Epoch 2/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 1.2612 - accuracy: 0.5694 - val_loss: 2.2071 - val_accuracy: 0.4019\n",
            "Epoch 3/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 1.0653 - accuracy: 0.6342 - val_loss: 0.9997 - val_accuracy: 0.6495\n",
            "Epoch 4/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.8919 - accuracy: 0.7012 - val_loss: 0.8101 - val_accuracy: 0.7164\n",
            "Epoch 5/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.7536 - accuracy: 0.7466 - val_loss: 1.2134 - val_accuracy: 0.6295\n",
            "Epoch 6/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.6400 - accuracy: 0.7827 - val_loss: 0.8035 - val_accuracy: 0.7346\n",
            "Epoch 7/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.5526 - accuracy: 0.8163 - val_loss: 0.6130 - val_accuracy: 0.7833\n",
            "Epoch 8/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.5063 - accuracy: 0.8322 - val_loss: 2.0118 - val_accuracy: 0.4948\n",
            "Epoch 9/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.4286 - accuracy: 0.8554 - val_loss: 0.5998 - val_accuracy: 0.7947\n",
            "Epoch 10/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.3921 - accuracy: 0.8689 - val_loss: 0.9593 - val_accuracy: 0.7210\n",
            "Epoch 11/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.3458 - accuracy: 0.8878 - val_loss: 0.5353 - val_accuracy: 0.8225\n",
            "Epoch 12/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.3146 - accuracy: 0.8955 - val_loss: 0.8078 - val_accuracy: 0.7647\n",
            "Epoch 13/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2987 - accuracy: 0.8982 - val_loss: 0.3622 - val_accuracy: 0.8789\n",
            "Epoch 14/200\n",
            "586/586 [==============================] - 4s 7ms/step - loss: 0.2701 - accuracy: 0.9108 - val_loss: 1.0321 - val_accuracy: 0.7214\n",
            "Epoch 15/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2543 - accuracy: 0.9165 - val_loss: 0.4748 - val_accuracy: 0.8462\n",
            "Epoch 16/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2401 - accuracy: 0.9210 - val_loss: 0.6757 - val_accuracy: 0.7811\n",
            "Epoch 17/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2149 - accuracy: 0.9300 - val_loss: 0.3124 - val_accuracy: 0.8944\n",
            "Epoch 18/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2157 - accuracy: 0.9291 - val_loss: 0.4248 - val_accuracy: 0.8716\n",
            "Epoch 19/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.2007 - accuracy: 0.9326 - val_loss: 0.2909 - val_accuracy: 0.9058\n",
            "Epoch 20/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1809 - accuracy: 0.9374 - val_loss: 0.2319 - val_accuracy: 0.9162\n",
            "Epoch 21/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1681 - accuracy: 0.9465 - val_loss: 0.5704 - val_accuracy: 0.8416\n",
            "Epoch 22/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1542 - accuracy: 0.9518 - val_loss: 0.2092 - val_accuracy: 0.9381\n",
            "Epoch 23/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1629 - accuracy: 0.9465 - val_loss: 0.3078 - val_accuracy: 0.9003\n",
            "Epoch 24/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1645 - accuracy: 0.9467 - val_loss: 0.1611 - val_accuracy: 0.9536\n",
            "Epoch 25/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1666 - accuracy: 0.9447 - val_loss: 0.3150 - val_accuracy: 0.9135\n",
            "Epoch 26/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1528 - accuracy: 0.9514 - val_loss: 0.5157 - val_accuracy: 0.8421\n",
            "Epoch 27/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1376 - accuracy: 0.9562 - val_loss: 0.2229 - val_accuracy: 0.9386\n",
            "Epoch 28/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1373 - accuracy: 0.9545 - val_loss: 0.8104 - val_accuracy: 0.8002\n",
            "Epoch 29/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1392 - accuracy: 0.9560 - val_loss: 0.2297 - val_accuracy: 0.9208\n",
            "Epoch 30/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1266 - accuracy: 0.9578 - val_loss: 0.4196 - val_accuracy: 0.8653\n",
            "Epoch 31/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1353 - accuracy: 0.9590 - val_loss: 0.2944 - val_accuracy: 0.9112\n",
            "Epoch 32/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1138 - accuracy: 0.9606 - val_loss: 0.4387 - val_accuracy: 0.8817\n",
            "Epoch 33/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1268 - accuracy: 0.9594 - val_loss: 0.1583 - val_accuracy: 0.9568\n",
            "Epoch 34/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1299 - accuracy: 0.9581 - val_loss: 0.1700 - val_accuracy: 0.9522\n",
            "Epoch 35/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1060 - accuracy: 0.9638 - val_loss: 0.1952 - val_accuracy: 0.9549\n",
            "Epoch 36/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1105 - accuracy: 0.9640 - val_loss: 0.1688 - val_accuracy: 0.9467\n",
            "Epoch 37/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1084 - accuracy: 0.9634 - val_loss: 0.2005 - val_accuracy: 0.9354\n",
            "Epoch 38/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1031 - accuracy: 0.9655 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
            "Epoch 39/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.1240 - accuracy: 0.9601 - val_loss: 0.3949 - val_accuracy: 0.8848\n",
            "Epoch 40/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.0932 - accuracy: 0.9686 - val_loss: 0.1955 - val_accuracy: 0.9376\n",
            "Epoch 41/200\n",
            "586/586 [==============================] - 4s 6ms/step - loss: 0.0918 - accuracy: 0.9690 - val_loss: 0.4379 - val_accuracy: 0.8744\n",
            "Epoch 42/200\n",
            "402/586 [===================>..........] - ETA: 1s - loss: 0.0957 - accuracy: 0.9695"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-89f8e187caa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Start Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m model_training_history = model.fit(x = features_train_shuffle, y = one_hot_encoded_erix_labels_train_shuffle, epochs = 200, \n\u001b[0;32m---> 30\u001b[0;31m                                    batch_size = 15 , shuffle = True, validation_split = 0.2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# erix added, evaluation(baseline):\n",
        "model_evaluation_history = model.evaluate(features_test, one_hot_encoded_labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByksNDGWSvq3",
        "outputId": "ceef3331-e0f8-405b-fcfb-ba47765da7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 0s 4ms/step - loss: 4.8858 - accuracy: 0.4439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Erix vgg (Ken's codes)\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "# load model\n",
        "\n",
        "...\n",
        "# load model without output layer\n",
        "model = VGG16(include_top=False)\n",
        "model.trainable=False # True # False\n",
        "\n",
        "import keras\n",
        "inputs = keras.Input(shape=(64, 64, 3))\n",
        "x = model(inputs)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_model\")\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005) # erix note: adjusted this\n",
        "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKzAIytkDxWV",
        "outputId": "d51aa971-02b3-4a62-82db-0782bf7228a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_5   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Start Training\n",
        "# note batch size is 32.\n",
        "model_training_history_resnet = model.fit(x = features_train_shuffle, y = one_hot_encoded_erix_labels_train_shuffle, epochs = 200, \n",
        "                                   batch_size = 32 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r_xuejxES-n",
        "outputId": "3a27eaec-cbde-47a3-99d1-47a2c68357a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "275/275 [==============================] - 5s 17ms/step - loss: 1.0854 - accuracy: 0.6438 - val_loss: 0.8010 - val_accuracy: 0.7319\n",
            "Epoch 2/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.6480 - accuracy: 0.8001 - val_loss: 0.6169 - val_accuracy: 0.7915\n",
            "Epoch 3/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.4992 - accuracy: 0.8534 - val_loss: 0.5271 - val_accuracy: 0.8361\n",
            "Epoch 4/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.4276 - accuracy: 0.8727 - val_loss: 0.4816 - val_accuracy: 0.8471\n",
            "Epoch 5/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3685 - accuracy: 0.8954 - val_loss: 0.4306 - val_accuracy: 0.8621\n",
            "Epoch 6/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3275 - accuracy: 0.9052 - val_loss: 0.3829 - val_accuracy: 0.8844\n",
            "Epoch 7/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3007 - accuracy: 0.9162 - val_loss: 0.3543 - val_accuracy: 0.8976\n",
            "Epoch 8/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2755 - accuracy: 0.9246 - val_loss: 0.3519 - val_accuracy: 0.8990\n",
            "Epoch 9/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2550 - accuracy: 0.9290 - val_loss: 0.3230 - val_accuracy: 0.9081\n",
            "Epoch 10/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2408 - accuracy: 0.9338 - val_loss: 0.3352 - val_accuracy: 0.9053\n",
            "Epoch 11/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2204 - accuracy: 0.9400 - val_loss: 0.3189 - val_accuracy: 0.9112\n",
            "Epoch 12/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2105 - accuracy: 0.9437 - val_loss: 0.3261 - val_accuracy: 0.9049\n",
            "Epoch 13/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1992 - accuracy: 0.9480 - val_loss: 0.2880 - val_accuracy: 0.9176\n",
            "Epoch 14/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1866 - accuracy: 0.9510 - val_loss: 0.2972 - val_accuracy: 0.9135\n",
            "Epoch 15/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1847 - accuracy: 0.9473 - val_loss: 0.3031 - val_accuracy: 0.9103\n",
            "Epoch 16/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1713 - accuracy: 0.9551 - val_loss: 0.3021 - val_accuracy: 0.9117\n",
            "Epoch 17/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1662 - accuracy: 0.9546 - val_loss: 0.3124 - val_accuracy: 0.9112\n",
            "Epoch 18/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1609 - accuracy: 0.9569 - val_loss: 0.3135 - val_accuracy: 0.9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# erix added, evaluation:\n",
        "model_evaluation_history_resnet = model.evaluate(features_test, one_hot_encoded_labels_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUu1nJouExVH",
        "outputId": "ae69d2f9-6748-4949-ccb9-f1040c18f0b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 1s 12ms/step - loss: 2.6967 - accuracy: 0.4394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lower learning rate\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Start Training\n",
        "# note batch size is 32.\n",
        "model_training_history_resnet = model.fit(x = features_train_shuffle, y = one_hot_encoded_erix_labels_train_shuffle, epochs = 200, \n",
        "                                   batch_size = 32 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])\n",
        "# erix added, evaluation:\n",
        "model_evaluation_history_resnet = model.evaluate(features_test, one_hot_encoded_labels_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRw4DKHyFrsA",
        "outputId": "bcdfbc6e-76dd-42e2-ab36-289bc9162b87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "275/275 [==============================] - 5s 16ms/step - loss: 1.2291 - accuracy: 0.6059 - val_loss: 0.9099 - val_accuracy: 0.7119\n",
            "Epoch 2/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.7930 - accuracy: 0.7607 - val_loss: 0.7203 - val_accuracy: 0.7715\n",
            "Epoch 3/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.6400 - accuracy: 0.8080 - val_loss: 0.6234 - val_accuracy: 0.8152\n",
            "Epoch 4/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.5493 - accuracy: 0.8426 - val_loss: 0.5562 - val_accuracy: 0.8330\n",
            "Epoch 5/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.4856 - accuracy: 0.8631 - val_loss: 0.5370 - val_accuracy: 0.8261\n",
            "Epoch 6/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.4368 - accuracy: 0.8754 - val_loss: 0.4769 - val_accuracy: 0.8557\n",
            "Epoch 7/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3996 - accuracy: 0.8877 - val_loss: 0.4380 - val_accuracy: 0.8721\n",
            "Epoch 8/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3688 - accuracy: 0.9013 - val_loss: 0.4240 - val_accuracy: 0.8748\n",
            "Epoch 9/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3458 - accuracy: 0.9069 - val_loss: 0.4029 - val_accuracy: 0.8794\n",
            "Epoch 10/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3225 - accuracy: 0.9148 - val_loss: 0.3800 - val_accuracy: 0.8889\n",
            "Epoch 11/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.3017 - accuracy: 0.9214 - val_loss: 0.3672 - val_accuracy: 0.8962\n",
            "Epoch 12/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2867 - accuracy: 0.9277 - val_loss: 0.3793 - val_accuracy: 0.8867\n",
            "Epoch 13/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2727 - accuracy: 0.9304 - val_loss: 0.3457 - val_accuracy: 0.9030\n",
            "Epoch 14/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2580 - accuracy: 0.9348 - val_loss: 0.3364 - val_accuracy: 0.9035\n",
            "Epoch 15/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2503 - accuracy: 0.9339 - val_loss: 0.3315 - val_accuracy: 0.9099\n",
            "Epoch 16/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2353 - accuracy: 0.9413 - val_loss: 0.3333 - val_accuracy: 0.8980\n",
            "Epoch 17/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2278 - accuracy: 0.9409 - val_loss: 0.3265 - val_accuracy: 0.9044\n",
            "Epoch 18/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2205 - accuracy: 0.9447 - val_loss: 0.3092 - val_accuracy: 0.9135\n",
            "Epoch 19/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2082 - accuracy: 0.9497 - val_loss: 0.3036 - val_accuracy: 0.9140\n",
            "Epoch 20/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.2035 - accuracy: 0.9494 - val_loss: 0.3004 - val_accuracy: 0.9144\n",
            "Epoch 21/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1958 - accuracy: 0.9519 - val_loss: 0.2977 - val_accuracy: 0.9153\n",
            "Epoch 22/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1878 - accuracy: 0.9539 - val_loss: 0.3019 - val_accuracy: 0.9117\n",
            "Epoch 23/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1798 - accuracy: 0.9569 - val_loss: 0.2896 - val_accuracy: 0.9217\n",
            "Epoch 24/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1748 - accuracy: 0.9587 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
            "Epoch 25/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1702 - accuracy: 0.9564 - val_loss: 0.2905 - val_accuracy: 0.9176\n",
            "Epoch 26/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1651 - accuracy: 0.9598 - val_loss: 0.2863 - val_accuracy: 0.9153\n",
            "Epoch 27/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1606 - accuracy: 0.9626 - val_loss: 0.2777 - val_accuracy: 0.9240\n",
            "Epoch 28/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1558 - accuracy: 0.9623 - val_loss: 0.2795 - val_accuracy: 0.9199\n",
            "Epoch 29/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1531 - accuracy: 0.9619 - val_loss: 0.2843 - val_accuracy: 0.9244\n",
            "Epoch 30/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1498 - accuracy: 0.9640 - val_loss: 0.2972 - val_accuracy: 0.9067\n",
            "Epoch 31/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1442 - accuracy: 0.9664 - val_loss: 0.2790 - val_accuracy: 0.9208\n",
            "Epoch 32/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1412 - accuracy: 0.9656 - val_loss: 0.2660 - val_accuracy: 0.9231\n",
            "Epoch 33/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1349 - accuracy: 0.9693 - val_loss: 0.2677 - val_accuracy: 0.9281\n",
            "Epoch 34/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1348 - accuracy: 0.9670 - val_loss: 0.2842 - val_accuracy: 0.9267\n",
            "Epoch 35/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1303 - accuracy: 0.9675 - val_loss: 0.2743 - val_accuracy: 0.9244\n",
            "Epoch 36/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1274 - accuracy: 0.9693 - val_loss: 0.2678 - val_accuracy: 0.9276\n",
            "Epoch 37/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1254 - accuracy: 0.9688 - val_loss: 0.2569 - val_accuracy: 0.9358\n",
            "Epoch 38/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1220 - accuracy: 0.9703 - val_loss: 0.2621 - val_accuracy: 0.9285\n",
            "Epoch 39/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1192 - accuracy: 0.9711 - val_loss: 0.2825 - val_accuracy: 0.9153\n",
            "Epoch 40/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1183 - accuracy: 0.9730 - val_loss: 0.2631 - val_accuracy: 0.9267\n",
            "Epoch 41/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1141 - accuracy: 0.9746 - val_loss: 0.2718 - val_accuracy: 0.9299\n",
            "Epoch 42/200\n",
            "275/275 [==============================] - 4s 14ms/step - loss: 0.1132 - accuracy: 0.9750 - val_loss: 0.2655 - val_accuracy: 0.9299\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 3.3214 - accuracy: 0.4270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Previous: \n",
        "\n",
        "the old dataset: 2000 frames for each class (27*2000 = 54k frames)\n",
        "then: split training & testing set\n",
        "\n",
        "problem: frames in train&test sets can be from the same videos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "split videos -> training & testing videos\n",
        "\n",
        "train the model on : only the frames in training-videos\n",
        "\n",
        "true test set: frames from unseen videos\n",
        "\n",
        "\n",
        "\n",
        "# \n",
        "40 - ~200 frames per video\n",
        "13 frames per video ()\n",
        "\n",
        "# \n",
        "reducing the number of classes 27 -> 10?\n",
        "\n",
        "\n",
        "\n",
        "# \n",
        "\n",
        "[ 13 frames for each video ] ( for LSTM? )\n",
        "\n",
        "\n",
        "1. frame dataset: each training sample is a frame.\n",
        "    ### video label will be the most common predicted label for 13 frames.\n",
        "\n",
        "2. list_of_frame dataset: each training sample is of 13 frames (or any other number)\n"
      ],
      "metadata": {
        "id": "cZeeSFvuTMns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7HwPjV5WcDs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erix added, Ken's model\n",
        "import keras\n",
        "\n",
        "resnet_50 = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet')\n",
        "resnet_50.trainable=True\n",
        "\n",
        "inputs = keras.Input(shape=(64, 64, 3))\n",
        "x = resnet_50(inputs)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_model\")\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) # erix note: adjusted this\n",
        "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XzZ-NYiSUz2",
        "outputId": "aad74386-8038-43a4-ab99-8514a17c0da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Erix added, Ken's model, training\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Start Training\n",
        "# note batch size is 15.\n",
        "model_training_history_resnet = model.fit(x = features_train_shuffle, y = one_hot_encoded_erix_labels_train_shuffle, epochs = 200, \n",
        "                                   batch_size = 15 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtH4bQebcqMI",
        "outputId": "02ace4ef-91f8-448b-f697-b621a13b170f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "586/586 [==============================] - 30s 42ms/step - loss: 0.5037 - accuracy: 0.8456 - val_loss: 3.8204 - val_accuracy: 0.1220\n",
            "Epoch 2/200\n",
            "586/586 [==============================] - 23s 40ms/step - loss: 0.0650 - accuracy: 0.9836 - val_loss: 0.0899 - val_accuracy: 0.9795\n",
            "Epoch 3/200\n",
            "586/586 [==============================] - 23s 40ms/step - loss: 0.0560 - accuracy: 0.9841 - val_loss: 0.0646 - val_accuracy: 0.9841\n",
            "Epoch 4/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0495 - accuracy: 0.9863 - val_loss: 0.0749 - val_accuracy: 0.9804\n",
            "Epoch 5/200\n",
            "586/586 [==============================] - 22s 38ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0604 - val_accuracy: 0.9868\n",
            "Epoch 6/200\n",
            "586/586 [==============================] - 22s 38ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0671 - val_accuracy: 0.9863\n",
            "Epoch 7/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.0649 - val_accuracy: 0.9868\n",
            "Epoch 8/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0298 - accuracy: 0.9929 - val_loss: 0.0469 - val_accuracy: 0.9900\n",
            "Epoch 9/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0609 - val_accuracy: 0.9854\n",
            "Epoch 10/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0494 - val_accuracy: 0.9886\n",
            "Epoch 11/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.0403 - val_accuracy: 0.9891\n",
            "Epoch 12/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.0588 - val_accuracy: 0.9868\n",
            "Epoch 13/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.0705 - val_accuracy: 0.9841\n",
            "Epoch 14/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 0.1251 - val_accuracy: 0.9690\n",
            "Epoch 15/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
            "Epoch 16/200\n",
            "586/586 [==============================] - 23s 39ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# erix added, evaluation:\n",
        "model_evaluation_history_resnet = model.evaluate(features_test, one_hot_encoded_labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WonXyFf4hJbp",
        "outputId": "1ae281ed-1fb5-47c6-e267-390fb26f18a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 2s 18ms/step - loss: 2.0893 - accuracy: 0.5182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The rest is not important - Erix noted"
      ],
      "metadata": {
        "id": "Zu2DKU1SeONK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erix dataset processing:\n",
        "Problem:  RAM crashes easily!\n",
        "\n",
        "My goal: split new training and test datasets s.t. we have a list of frames for a video as a single sample. \n",
        "\n",
        "How: Firstly, I split training videos and test videos. For each video, I extract some number of frames (Currently using 13 frames/video)\n",
        "\n",
        "Problem with the original notebook design: frames from the same video can appear in both training&test set\n",
        "\n",
        "New evaluation method: Firstly, we'll evaluate only on the frames of the unseen videos. There's 13 frames per video. \n",
        "IF WE ONLY CLASSIFY FRAMES,we'll predict 13 labels for 13 frames and return the most common label for each video.\n",
        "IF the input of the model is a list of frames(13 frames), then just use the model's output.\n",
        "\n"
      ],
      "metadata": {
        "id": "Cna0vdJx0iri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# erix notes: experimenting training on small dataset\n",
        "\n",
        "# 4*27*40/5*.8(validation costs 20%) = 691 batches per epoch~\n",
        "\n",
        "class_idx_map = {}\n",
        "# convert \n",
        "for idx, c in enumerate(classes_list):\n",
        "    class_idx_map[c] = idx\n",
        "# sampled_features\n",
        "one_hot_encoded_sampled_labels = to_categorical(list(map(lambda x: class_idx_map[x], sampled_labels)))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = sampled_features, y = one_hot_encoded_sampled_labels, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DGLZ0d7SukN7",
        "outputId": "ef9b7916-8db4-4f9e-f49b-2d222438f5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "692/692 [==============================] - 18s 6ms/step - loss: 1.8633 - accuracy: 0.4586 - val_loss: 7.6005 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.8153 - accuracy: 0.7578 - val_loss: 8.5306 - val_accuracy: 0.0741\n",
            "Epoch 3/200\n",
            "692/692 [==============================] - 4s 6ms/step - loss: 0.4869 - accuracy: 0.8478 - val_loss: 11.6451 - val_accuracy: 0.0741\n",
            "Epoch 4/200\n",
            "692/692 [==============================] - 4s 6ms/step - loss: 0.2644 - accuracy: 0.9216 - val_loss: 11.0224 - val_accuracy: 0.0556\n",
            "Epoch 5/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.2212 - accuracy: 0.9410 - val_loss: 10.5187 - val_accuracy: 0.0498\n",
            "Epoch 6/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.2008 - accuracy: 0.9433 - val_loss: 13.1875 - val_accuracy: 0.0741\n",
            "Epoch 7/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.1549 - accuracy: 0.9543 - val_loss: 11.6808 - val_accuracy: 0.0741\n",
            "Epoch 8/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.1408 - accuracy: 0.9583 - val_loss: 17.8974 - val_accuracy: 0.0671\n",
            "Epoch 9/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9566 - val_loss: 17.1844 - val_accuracy: 0.0741\n",
            "Epoch 10/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 14.2237 - val_accuracy: 0.0741\n",
            "Epoch 11/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1071 - accuracy: 0.9690 - val_loss: 18.8957 - val_accuracy: 0.0741\n",
            "Epoch 12/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0913 - accuracy: 0.9748 - val_loss: 15.8341 - val_accuracy: 0.0741\n",
            "Epoch 13/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.1101 - accuracy: 0.9647 - val_loss: 19.6848 - val_accuracy: 0.0706\n",
            "Epoch 14/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0871 - accuracy: 0.9725 - val_loss: 22.9479 - val_accuracy: 0.0741\n",
            "Epoch 15/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.1032 - accuracy: 0.9702 - val_loss: 21.3433 - val_accuracy: 0.0741\n",
            "Epoch 16/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0692 - accuracy: 0.9803 - val_loss: 18.1614 - val_accuracy: 0.0741\n",
            "Epoch 17/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 28.2633 - val_accuracy: 0.0741\n",
            "Epoch 18/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0571 - accuracy: 0.9835 - val_loss: 22.9874 - val_accuracy: 0.0741\n",
            "Epoch 19/200\n",
            "692/692 [==============================] - 4s 6ms/step - loss: 0.0594 - accuracy: 0.9818 - val_loss: 24.2453 - val_accuracy: 0.0417\n",
            "Epoch 20/200\n",
            "692/692 [==============================] - 4s 6ms/step - loss: 0.0890 - accuracy: 0.9722 - val_loss: 26.9701 - val_accuracy: 0.0741\n",
            "Epoch 21/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 23.7564 - val_accuracy: 0.0741\n",
            "Epoch 22/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0605 - accuracy: 0.9821 - val_loss: 18.1203 - val_accuracy: 0.0741\n",
            "Epoch 23/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 19.9224 - val_accuracy: 0.0741\n",
            "Epoch 24/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 20.3176 - val_accuracy: 0.0741\n",
            "Epoch 25/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0614 - accuracy: 0.9835 - val_loss: 20.3074 - val_accuracy: 0.0741\n",
            "Epoch 26/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 24.6602 - val_accuracy: 0.0741\n",
            "Epoch 27/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 22.0003 - val_accuracy: 0.0741\n",
            "Epoch 28/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 25.1989 - val_accuracy: 0.0741\n",
            "Epoch 29/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0651 - accuracy: 0.9815 - val_loss: 30.4365 - val_accuracy: 0.0741\n",
            "Epoch 30/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 24.1487 - val_accuracy: 0.1204\n",
            "Epoch 31/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 27.9186 - val_accuracy: 0.1204\n",
            "Epoch 32/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0495 - accuracy: 0.9855 - val_loss: 25.3268 - val_accuracy: 0.1204\n",
            "Epoch 33/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 26.1041 - val_accuracy: 0.1030\n",
            "Epoch 34/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 20.0643 - val_accuracy: 0.1215\n",
            "Epoch 35/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 23.8507 - val_accuracy: 0.0741\n",
            "Epoch 36/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 30.5301 - val_accuracy: 0.1204\n",
            "Epoch 37/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 26.7593 - val_accuracy: 0.1204\n",
            "Epoch 38/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 24.7764 - val_accuracy: 0.1204\n",
            "Epoch 39/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 24.1324 - val_accuracy: 0.0741\n",
            "Epoch 40/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 32.0734 - val_accuracy: 0.0741\n",
            "Epoch 41/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 26.5960 - val_accuracy: 0.0012\n",
            "Epoch 42/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 26.3183 - val_accuracy: 0.0741\n",
            "Epoch 43/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 29.5954 - val_accuracy: 0.0741\n",
            "Epoch 44/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0457 - accuracy: 0.9876 - val_loss: 30.8412 - val_accuracy: 0.0741\n",
            "Epoch 45/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 30.2194 - val_accuracy: 0.0741\n",
            "Epoch 46/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 30.6621 - val_accuracy: 0.0741\n",
            "Epoch 47/200\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 34.8011 - val_accuracy: 0.0741\n",
            "Epoch 48/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 35.7025 - val_accuracy: 0.0741\n",
            "Epoch 49/200\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 32.1172 - val_accuracy: 0.0741\n",
            "Epoch 50/200\n",
            "517/692 [=====================>........] - ETA: 0s - loss: 0.0302 - accuracy: 0.9926"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fd080bc85dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Start Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_training_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encoded_sampled_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CawAOc04uvFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_training_frames(features_train, one_hot_labels_train):\n",
        "\n",
        "    _,__, labels_train_kept, labels_train_kept = train_test_split(features_train, \n",
        "                                                                                one_hot_labels_train, test_size = 0.05, shuffle = True)\n",
        "    return labels_train_kept, labels_train_kept\n",
        "\n",
        "labels_train_kept, labels_train_kept = sample_training_frames(features_train, one_hot_encoded_labels_train)"
      ],
      "metadata": {
        "id": "eEbbquHZgwfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Erix added . Training\n",
        "class_idx_map = {}\n",
        "# convert \n",
        "for idx, c in enumerate(classes_list):\n",
        "    class_idx_map[c] = idx\n",
        "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels_train = to_categorical(list(map(lambda x: class_idx_map[x], labels_train)))\n",
        "one_hot_encoded_labels_test = to_categorical(list(map(lambda x: class_idx_map[x], labels_test)))\n",
        "# erix  edited\n",
        "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
        "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
        "#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Adding loss, optimizer and metrics values to the model.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = features_train, y = one_hot_encoded_labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2)\n",
        "#model_training_history = model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "id": "SqqXs7OjMSQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ju_Mq42yQhqN",
        "outputId": "d19ffcb5-cbc9-4850-c8ba-3fa9367e5506",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6912/6912 [==============================] - 38s 4ms/step - loss: 2.8862 - accuracy: 0.1686 - val_loss: 2.8645 - val_accuracy: 0.2303\n",
            "Epoch 2/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 2.4793 - accuracy: 0.2736 - val_loss: 2.5381 - val_accuracy: 0.3201\n",
            "Epoch 3/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 2.2475 - accuracy: 0.3463 - val_loss: 2.4518 - val_accuracy: 0.3713\n",
            "Epoch 4/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 2.0733 - accuracy: 0.3980 - val_loss: 2.3936 - val_accuracy: 0.4046\n",
            "Epoch 5/200\n",
            "6912/6912 [==============================] - 26s 4ms/step - loss: 1.9567 - accuracy: 0.4301 - val_loss: 2.7502 - val_accuracy: 0.3936\n",
            "Epoch 6/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.8505 - accuracy: 0.4642 - val_loss: 2.1568 - val_accuracy: 0.4999\n",
            "Epoch 7/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.7690 - accuracy: 0.4882 - val_loss: 2.4112 - val_accuracy: 0.4788\n",
            "Epoch 8/200\n",
            "6912/6912 [==============================] - 26s 4ms/step - loss: 1.7131 - accuracy: 0.5034 - val_loss: 2.0200 - val_accuracy: 0.5372\n",
            "Epoch 9/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.6597 - accuracy: 0.5161 - val_loss: 2.1838 - val_accuracy: 0.5127\n",
            "Epoch 10/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.6046 - accuracy: 0.5334 - val_loss: 2.1899 - val_accuracy: 0.5753\n",
            "Epoch 11/200\n",
            "6912/6912 [==============================] - 26s 4ms/step - loss: 1.5678 - accuracy: 0.5424 - val_loss: 2.4765 - val_accuracy: 0.5698\n",
            "Epoch 12/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.5322 - accuracy: 0.5517 - val_loss: 2.5148 - val_accuracy: 0.5499\n",
            "Epoch 13/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.4967 - accuracy: 0.5604 - val_loss: 3.4887 - val_accuracy: 0.4845\n",
            "Epoch 14/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.4753 - accuracy: 0.5710 - val_loss: 2.0732 - val_accuracy: 0.6391\n",
            "Epoch 15/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.4586 - accuracy: 0.5713 - val_loss: 2.3170 - val_accuracy: 0.5919\n",
            "Epoch 16/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.4337 - accuracy: 0.5827 - val_loss: 2.5378 - val_accuracy: 0.5372\n",
            "Epoch 17/200\n",
            "6912/6912 [==============================] - 27s 4ms/step - loss: 1.4071 - accuracy: 0.5872 - val_loss: 2.3217 - val_accuracy: 0.5804\n",
            "Epoch 18/200\n",
            "6459/6912 [===========================>..] - ETA: 1s - loss: 1.3815 - accuracy: 0.5946"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a3dbbf6223ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\\n# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\\n#early_stopping_callback = EarlyStopping(monitor = \\'val_loss\\', patience = 15, mode = \\'min\\', restore_best_weights = True)\\n\\n# Adding loss, optimizer and metrics values to the model.\\nmodel.compile(loss = \\'categorical_crossentropy\\', optimizer = \\'Adam\\', metrics = [\"accuracy\"])\\n\\n# Start Training\\nmodel_training_history = model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2)\\n#model_training_history = model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
        "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
        "#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Adding loss, optimizer and metrics values to the model.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2)\n",
        "#model_training_history = model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 5 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74tGjokkmSHR",
        "outputId": "22b56794-6600-4cd7-e732-c1ac34b95200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308/308 [==============================] - 2s 6ms/step - loss: 4.5731 - accuracy: 0.1988\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, one_hot_encoded_labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hSxDkoBlNqu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "40c691d1-117a-4024-a211-de0b315c9a40"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-2cfbc22e3160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1978\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1248\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H71rf2KoIiG"
      },
      "outputs": [],
      "source": [
        "y_pred=np.argmax(y_pred, axis=1)\n",
        "labels_test=np.argmax(labels_test, axis=1)\n",
        "print(classification_report(labels_test,y_pred,target_names=classes_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLo3T6xPuJdK"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dryJ5BSSvsvj"
      },
      "outputs": [],
      "source": [
        "print('Train Accuracy of Model is {} and Test Accuracy of Model is {}'.format(model_training_history.history['accuracy'][-1],model_evaluation_history[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKaPU9EXrJ6b"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=[7,6])\n",
        "sns.heatmap(cm,cmap=\"Reds\", annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1BpST9ErsHY",
        "outputId": "cf80b0d0-d8b2-4de4-d37c-1d330d1bcd2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([16,  7,  8, ...,  1,  0, 20])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrQnmVF7aZjQ"
      },
      "outputs": [],
      "source": [
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "    # Get Metric values using metric names as identifiers\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "    # Constructing a range object which will be used as time \n",
        "    epochs = range(len(metric_value_1))\n",
        "  \n",
        "    # Plotting the Graph\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "  \n",
        "    # Adding title to the plot\n",
        "    plt.title(str(plot_name))\n",
        "    #Saving the Plot\n",
        "    plt.savefig(str(plot_name)+\".png\")\n",
        "    # Adding legend to the plot\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKABbscJblP_"
      },
      "outputs": [],
      "source": [
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTSpJP-bb7WV"
      },
      "outputs": [],
      "source": [
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions"
      ],
      "metadata": {
        "id": "EeNuR0mrd_RO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuYNydSNPZjh"
      },
      "outputs": [],
      "source": [
        "def predict_on_uploaded_video(video_file_path, output_file_path, window_size):\n",
        "\n",
        "\n",
        "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
        "\n",
        "    # Reading the Video File using the VideoCapture Object\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Getting the width and height of the video \n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
        "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
        "\n",
        "    while True: \n",
        "\n",
        "        # Reading The Frame\n",
        "        status, frame = video_reader.read() \n",
        "\n",
        "        if not status:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
        "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
        "\n",
        "        # Appending predicted label probabilities to the deque object\n",
        "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
        "\n",
        "        # Assuring that the Deque is completely filled before starting the averaging process\n",
        "        if len(predicted_labels_probabilities_deque) == window_size:\n",
        "\n",
        "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
        "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
        "\n",
        "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
        "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
        "\n",
        "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
        "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
        "\n",
        "            # Accessing The Class Name using predicted label.\n",
        "            predicted_class_name = classes_list[predicted_label]\n",
        "          \n",
        "            # Overlaying Class Name Text Ontop of the Frame\n",
        "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Writing The Frame\n",
        "        video_writer.write(frame)\n",
        "    \n",
        "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
        "    video_reader.release()\n",
        "    video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIonkp3zu4IR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdHu4TSqLOUz"
      },
      "outputs": [],
      "source": [
        "predict_on_uploaded_video(\"#########.avi\",1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FINAL_Baseline_Action_Recognition_on_hmdb51_May4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}